{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import all necessary modules and set parameters\n",
    "from __future__ import print_function, absolute_import, division\n",
    "# load modules and cythonmagic\n",
    "import numpy as np\n",
    "from time import time\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define class Data. It will save all the necessary data for the problem\n",
    "# Example is about computing interaction between particles with given matrix of interactions\n",
    "class Data(object):\n",
    "    \"\"\"This is container for data for the problem.\"\"\"\n",
    "    \"\"\"First of all, it requires methods check_far, compute_aux, divide and __len__.\"\"\"\n",
    "    def __init__(self, particles, matrix):\n",
    "        \"\"\"save particles and matrix\"\"\"\n",
    "        self.particles = particles\n",
    "        self.matrix = matrix\n",
    "        # main requirement here is to set self.count -- number of particles and self.dim -- dimensionality of the problem\n",
    "        self.count, self.dim = particles.shape\n",
    "        \n",
    "    \"\"\"All other functions must have exactly the same parameters, as required.\"\"\"\n",
    "    \n",
    "    def check_far(self, bb0, bb1):\n",
    "        \"\"\"checks if bounding boxes bb0 and bb1 do not cross each other.\"\"\"\n",
    "        mean0 = bb0.mean(axis = 1)\n",
    "        mean1 = bb1.mean(axis = 1)\n",
    "        dist = np.linalg.norm(mean1-mean0)\n",
    "        diag = max(np.linalg.norm(bb0[:,1]-bb0[:,0]), np.linalg.norm(bb1[:,1]-bb1[:,0]))\n",
    "        return dist > diag\n",
    "    \n",
    "    def compute_aux(self, index):\n",
    "        \"\"\"computes bounding boxes, requires self.particles defined.\"\"\"\n",
    "        selected = self.particles[index]\n",
    "        return np.hstack([selected.min(axis = 0).reshape(3,1), selected.max(axis = 0).reshape(3,1)])\n",
    "\n",
    "    def divide(self, index):\n",
    "        \"\"\"divides cluster into subclusters.\"\"\"\n",
    "        vertex = self.particles[index].copy()\n",
    "        center = vertex.mean(axis = 0)\n",
    "        vertex -= center.reshape(1, self.dim)\n",
    "        normal = np.linalg.svd(vertex, full_matrices = 0)[2][0]\n",
    "        scal_dot = normal.dot(vertex.T)\n",
    "        permute = scal_dot.argsort()\n",
    "        scal_dot = scal_dot[permute]\n",
    "        k = scal_dot.searchsorted(0)\n",
    "        return permute, [0, k, permute.size]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "# this function generates matrix with elements: a[i,j] = 1/r(x[i], y[j]), where r(x,y) is a distance between points in 3d space\n",
    "def gen_matrix(x, y):\n",
    "    a = np.ndarray((x.shape[0], y.shape[0]))\n",
    "    cdef double [:,:] a_buf = a\n",
    "    cdef double [:,:] x_buf = x\n",
    "    cdef double [:,:] y_buf = y\n",
    "    cdef double z[3]\n",
    "    cdef double tmp\n",
    "    cdef int i, j\n",
    "    for i in range(x_buf.shape[0]):\n",
    "        for j in range(y_buf.shape[0]):\n",
    "            z[0] = x_buf[i,0]-y_buf[j,0]\n",
    "            z[1] = x_buf[i,1]-y_buf[j,1]\n",
    "            z[2] = x_buf[i,2]-y_buf[j,2]\n",
    "            tmp = z[0]*z[0]+z[1]*z[1]+z[2]*z[2]\n",
    "            if tmp < 1e-30:\n",
    "                a_buf[i, j] = 0.0\n",
    "            else:\n",
    "                a_buf[i, j] = tmp**(-0.5)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we generate 1000 particles randomly in cube [0;1]^3\n",
    "np.random.seed(0)\n",
    "particles = np.random.rand(1000, 3)\n",
    "# Let matrix of interactions be equal to 1/r\n",
    "dense_matrix = gen_matrix(particles, particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster trees are generated in 0.209475040436 seconds\n",
      "Depth level of each cluster tree: 8\n",
      "Row cluster tree\n",
      "    nodes : 115\n",
      "    leaves: 58\n",
      "Column cluster tree\n",
      "    nodes : 115\n",
      "    leaves: 58\n"
     ]
    }
   ],
   "source": [
    "# Generate object of class Data based on particles and matrix of interactions\n",
    "data = Data(particles, dense_matrix)\n",
    "\n",
    "# Initialize cluster trees with root node\n",
    "from h2tools import ClusterTree\n",
    "block_size = 25\n",
    "tree = ClusterTree(data, block_size)\n",
    "\n",
    "# Set function, that returns submatrix of the matrix of interactions\n",
    "def func(data1, rows, data2, columns):\n",
    "    return data1.matrix[rows][:,columns]\n",
    "\n",
    "# Hack to prevent bug of qr decomposition for 130x65 matrices (multithread mkl bug)\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "# Generate block cluster tree in variable `problem`\n",
    "from h2tools import Problem\n",
    "symmetric = 1\n",
    "verbose = True\n",
    "problem = Problem(func, tree, tree, symmetric, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MCBH, relative error parameter tau set to 1e-4\n",
      "Far-field interactions(MCBH method):\n",
      "    Function calls: 853\n",
      "    Function values computed: 849838\n",
      "    Function time, seconds: 0.03\n",
      "    Average time per function value, seconds: 2.95e-08\n",
      "    Maxvol time, seconds: 0.13267493248\n",
      "Near-field interactions:\n",
      "    Function calls: 501\n",
      "    Function values computed: 181023\n",
      "    Function time, seconds: 0.02\n",
      "    Average time per function value, seconds: 9.39e-08\n",
      "Total time, seconds: 0.20\n",
      "Memory:\n",
      "    Basises, MB: 0.02\n",
      "    Transfer matrices, MB: 0.13\n",
      "    Far-field interactions, MB: 0.14\n",
      "    Near-field interactions, MB: 0.12\n",
      "Total memory, MB: 0.41\n",
      "memory for uncompressed approximation: 0.406196594238 MB\n",
      "relative error of approximation: 0.000413797990161\n",
      "memory BEFORE SVD-compression: 0.41MB\n",
      "memory AFTER SVD-compression: 0.39MB\n",
      "recompression time: 0.162955999374\n",
      "relative error of far-field approximation: 0.00087821686283\n",
      "memory BEFORE SVD-compression: 0.39MB\n",
      "memory AFTER SVD-compression: 0.33MB\n",
      "recompression time: 0.15194606781\n",
      "relative error of far-field approximation: 0.00952428635044\n"
     ]
    }
   ],
   "source": [
    "# computing multicharge representation\n",
    "from __future__ import print_function\n",
    "\n",
    "from h2tools.mcbh import mcbh\n",
    "\n",
    "print('Computing MCBH, relative error parameter tau set to 1e-4')\n",
    "h2matrix = mcbh(problem, tau=1e-3, iters=1, onfly=0, verbose=1)\n",
    "print('memory for uncompressed approximation: '+str(h2matrix.nbytes()/1024./1024)+' MB')\n",
    "# error measure with pypropack\n",
    "print('relative error of approximation:', h2matrix.diffnorm(far_only=0))\n",
    "# compressing approximant\n",
    "h2matrix.svdcompress(1e-3, verbose=1)\n",
    "# error measure with pypropack\n",
    "print('relative error of far-field approximation:', h2matrix.diffnorm(far_only=1))\n",
    "\n",
    "h2matrix.svdcompress(1e-2, verbose=1)\n",
    "# error measure with pypropack\n",
    "print('relative error of far-field approximation:', h2matrix.diffnorm(far_only=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2matrix at 0x105357250\n",
      "    Structure (h2/mcbh): h2\n",
      "    Memory layout (low/full): full\n",
      "    Shape: [1000, 1000]\n",
      "    Total memory, MB: 0.33\n",
      "        Basises, MB: 0.00\n",
      "        Transfer matrices, MB: 0.07\n",
      "        Far-field interactions, MB: 0.14\n",
      "        Near-field interactions, MB: 0.12\n"
     ]
    }
   ],
   "source": [
    "print(h2matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
